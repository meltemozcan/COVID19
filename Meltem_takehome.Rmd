---
title: "takehome207"
author: "Meltem Ozcan"
date: "4/21/2020"
output: pdf_document

---
```{r}
library(dplyr)
library(RColorBrewer)
library(LearnBayes)
```

EXPLORATORY DATA ANALYSIS

```{r}
getwd()
data = read.delim('Covid19-04-13-20.txt', sep=',')

table(is.na(data))
#no missing values

data%>%glimpse()
#Four variables: Country (factor), Total.cases (int), Deaths (int), Population (int)

data%>%summary()
#We have data from 58 counties. 
```


Given the novelty of the virus, the lack of an established treatment, delays in reporting and widespread misinformation

```{r}
ord = order(data$Deaths)
data1 = data[ord, ]
tail(data1)

#Highest number of deaths is in LA with 320 deaths, followed by
#Santa Clara (60 deaths) and Riverside (50 deaths)
```

```{r}
ord = order(data$Total.cases)
data2 = data[ord, ]
tail(data2)

#LA has the highest number of cases (9420) followed by San Diego (1847) 
#and Riverside (1751).
```

```{r}
ord = order(data$Population)
data3 = data[ord, ]
tail(data3)

#The most populous counties are LA (10039108), San Diego (3337685),
#and Orange County (3190400).
```

We examine the totals for each variable:

```{r}
sum(data$Total.cases)
sum(data$Population)
sum(data$Deaths)
```
```{r}
table(data$Total.cases)
table(data$Deaths)
```




```{r}

par(las=2)

hist(data$Deaths, main = "Deaths", 
     xlab = "Number of deaths", col= brewer.pal(n =9, name="BuGn"))
```

The distribution of number of deaths is right skewed with an outlier. We do a log transformation and replot data.

```{r}
par(las=2)

hist(log(data$Deaths), main = "Log-Deaths", 
     xlab = "Log of number of deaths", col= brewer.pal(n = 9, name="BuGn"))
```

```{r}
par(las=2)

hist(data$Total.cases, main = "Total cases", 
     xlab = "Number of total cases", col= brewer.pal(n = 3, name="BuGn"))
```

```{r}
par(las=2)

hist(log(data$Total.cases), main = "Log-total cases", 
     xlab = "Log of number of total cases", col= brewer.pal(n = 9, name="BuGn"))
```



```{r}
par(las=1)

hist(data$Population, main = "Population", 
     xlab = "Number of people in the county", 
     col= brewer.pal(n = 3, name="BuGn"))
```

We see that LA is a potential outlier in terms of population, number of total cases, and number of deaths.

```{r}
par(las=2)
hist(data$Deaths, main = "COVID-19 deaths in CA", 
     xlab = "Number of deaths", 
   #  cex.main=0.8, cex.lab=0.8,cex.axis=0.6, 
     col= brewer.pal(n=9, name="Spectral"))
hist(data$Total.cases, main = "COVID-19 infections in CA", 
     xlab = "Number of cases",
   #  cex.main=0.8,cex.lab=0.8, cex.axis=0.6, 
     col= brewer.pal(n = 9, name="Spectral"))
```



```{r}
par(las=2)
plot(y=data$Deaths, x=data$Total.cases, xlab="Number of COVID-19 cases", ylab = "Number of COVID-19 deaths",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))
abline(lm(data$Deaths~data$Total.cases), lwd=0.8)


plot(y=log(data$Deaths), x=log(data$Total.cases),
     xlab="Log COVID-19 cases", ylab = "Log COVID-19 deaths",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))

plot(x=data$Deaths, y=data$Population,
     xlab="Number of COVID-19 deaths", ylab = "County opulation",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))
plot(x=log(data$Deaths), y=log(data$Population), 
     xlab="Log COVID-19 cases", ylab = "Log population",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))

plot(x=data$Population, y=data$Total.cases,
     xlab="County population", ylab = "Number of COVID-19 cases",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))
plot(x=log(data$Population), y=log(data$Total.cases),
     xlab="Log county population", ylab = "Log COVID-19 cases",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))
```


```{r}
#new variable indicating how much of the population was infected in each county
data$proportion_infected = data$Total.cases/data$Population

#new variable for mortality rate for each county
data$proportion_dead = data$Deaths/data$Total.cases
```



```{r}
par(las=2)
par(las=2)
plot(data$proportion_infected, xlab="Number of COVID-19 cases", ylab = "Number of COVID-19 deaths",pch=16,
     #cex.main=0.8, cex.lab=0.8, cex.axis=0.6,
     col= brewer.pal(n=9, name="Spectral"))
```

```{r}
par(las=1)

hist(data$proportion_infected, main = "Proportion infected", 
     xlab = "percentage", 
     col= brewer.pal(n = 3, name="BuGn"))
```


```{r}
par(las=1)

hist(data$proportion_dead, main = "Mortality rate by county", 
     xlab = "percentage", 
     col= brewer.pal(n = 3, name="BuGn"))
```


```{r}
#create variables in millions
data$Total.cases.m = data$Total.cases/1000000
data$Population.m = data$Population/1000000
data$Deaths.m = data$Deaths/1000000
```

```{r}
total_pop.m = sum(data$Population.m)
total_pop.m #CA population: 39.422.493

total_infected.m = sum(data$Total.cases.m)
total_infected.m #total infected in CA: 0.024303

total_pop = sum(data$Population)
total_pop #CA population: 39,422,493

total_infected = sum(data$Total.cases)
total_infected #total infected in CA: 0.024303
```


```{r}
set.seed(787)
```



BINOMIAL MODEL

The distribution of the number of deaths is given as 
$y_i \sim Bin(n_i, \theta)$ and the distribution of $\theta$, which is the probability of death from COVID 19, is given as $\theta \sim Be(1/2,1/2)$. Assuming independence between the counties, we calculate the posterior distribution of $\theta$ given $y$ as:

$$p(\theta|y) = p(y|\theta)p(\theta)$$
$$ \propto \prod_{i=1}^{58} \left[\theta^{y_i}(1-\theta)^{n_i-y_i} \right]\theta^{-1/2}(1-\theta)^{-1/2}$$
$$ \propto  \theta^{\sum_{i=1}^{58}y_i}(1-\theta)^{\sum_{i=1}^{58}n_i-\sum_{i=1}^{58}y_i}\theta^{-1/2}(1-\theta)^{-1/2}$$
$$ \propto  \theta^{\sum_{i=1}^{58}y_i-1/2}(1-\theta)^{\sum_{i=1}^{58}n_i-\sum_{i=1}^{58}y_i-1/2}$$

Thus, $\theta|y, n \sim Be(\sum_{i=1}^{58}y_i+1/2,\sum_{i=1}^{58}n_i-\sum_{i=1}^{58}y_i+1/2)$

Generate a random sample of 1000 thetas from the beta distribution:
```{r}
sum_ni= sum(data$Total.cases)
sum_yi= sum(data$Deaths)

p = seq(0,1, length=1000)
post_theta = dbeta(p,sum_yi+1/2,sum_ni-sum_yi+1/2)
```
```{r}
#plot the sampled thetas
par(las=2)
plot(p,post_theta, type="l", col="red",
     ylab="Density", xlab="theta", main="Density of theta|y")
```





We can calculate the posterior predictive distribution to make predictions for the number of infections in CA. We use the formula below:

$$p(\tilde y|y) = \int p(\tilde y,\theta|y)d\theta = \int p(\tilde y|\theta,y) p(\theta|y)d\theta$$
We are asked to assume that $20\%$ of the population will be infected.
```{r}
CA_pop=sum(data$Population)
future_infec_CA =round(CA_pop/5)
future_infec_CA #7884499
```

Assuming conditional independence between current number of deaths and future number of deaths: 
$$p(\tilde y|y) = \int p(\tilde y|\theta) p(\theta|y)d\theta$$

Now we draw samples from binomial:
```{r}
preds2=c() #initialize empty string

for(i in 1:1000){
  #Sample from the random thetas with replacement and draw from binomial
preds2=cbind(preds2,
             sum(rbinom(future_infec_CA,size=1,
                        sample(p ,1 , replace=TRUE,
                               prob=post_theta))))
}
```

```{r}
#plot predictions from model 1
par(las=1)
hist(preds2,main = "Predicted number of deaths in CA based on Model 1", 
     xlab = "Number of deaths",
     cex.lab=0.9, cex.axis=0.8, 
     col= brewer.pal(n = 9, name="BuGn"))

mean(preds2)
min(preds2)
max(preds2)
```


Question 2 BETA BINOMIAL

Consider a second model that assumes the possibility that the data are overdispersed:

$$y_i \sim BeBi(n_i,\mu, \tau), \;\;\;\;\;\; p(\mu, \tau)=(\mu(1-\mu)(1+\tau)^2)^{-1}$$
Use a rejection sampling approach to obtain samples from $p(\mu, \tau | \textbf{y})$ and apply your method to fit the California COVID 19 data. Are there any counties that are particularly influential in the analysis of the posterior for $\mu$? Are there any important differences between the results for this model and those for model (1)?

$$p(y_i|\mu, \tau) =  {n_i \choose y_i} \frac{B(\mu\tau+y_i, \tau(1-\mu)+n_i+y_i)}{B(\mu\tau,\tau(1-\mu))}$$

$$p(\textbf{y}|\mu, \tau) =  \prod_{i=1}^{58}{n_i \choose y_i} \frac{B(\mu\tau+y_i, \tau(1-\mu)+n_i+y_i)}{B(\mu\tau,\tau(1-\mu))}$$

We can compute the conditional posterior as below:
$$p(\mu, \tau | \textbf{y}) = p(\textbf{y}|\mu, \tau)p(\mu,\tau)$$
$$\propto  \prod_{i=1}^{58}\frac{B(\mu\tau+y_i, \tau(1-\mu)+n_i+y_i)}{B(\mu\tau,\tau(1-\mu))}\times \frac{1}{\mu(1-\mu)(1+\tau)^2}$$

We do not have a closed form for the target distribution of $p(\mu, \tau | \textbf{y})$. In order to achieve a sample from the posterior distribution, we can perform rejection sampling. As discussed in class and in the Jim Albert book, we will use a bivariate student t distribution as our proposal distribution q as this distribution is easy to sample from and has polynomially decaying tails that allow for more mass than the normal distribution. We will fix the location of the t at the mode, which we will estimate using Laplace approximation, and we will use an inflated covariance matrix as the scale matrix. Then we find the bounding  constant value c such that $p(\mu, \tau|y) \leq cq(\mu, \tau)$ for all $\mu$ and $\tau$. In log form, this is the same as maximizing  $log p(\mu, \tau|y) - log q(\mu, \tau)$ to find the constant d=log c such that $log p(\mu, \tau|y) - log q(\mu, \tau) \leq d$.

We begin with a reparameterization of $\mu$ and $\tau$ to the real line. We will log transform tau as it is positive valued, and logit transform mu as it is a proportion:

$$\theta_1= logit(\mu)=log\left(\frac{1}{1-\mu}\right)$$
$$\theta_2=log(\tau)$$
Then we can compute the posterior density of the transformed parameters by evaluating the density function at the inverse $\left(\frac{e^{\theta_1}}{1+e^{\theta_1}}, e^{\theta_2}\right)$ and multiplying by the Jacobian $\left(\frac{e^{\theta_1+\theta_2}}{(1+e^{\theta_1})^2} \right)$

We first write a function that computes the log transformed value of the posterior.

```{r}
data2 = cbind(data$Deaths,data$Total.cases)

logf= function(y, n,thetas){ 
  mu=thetas[1]
  tau=thetas[2]
    lbeta(tau*mu+y, tau*(1-mu)+n-y)-lbeta(tau*mu,
                                          tau*(1-mu))
}

#log transform tau and logit transform mu, and compute
#the transformed posterior density
transformed_post_betabin = function(thetas,data){
  mu=exp(thetas[1])/(1 + exp(thetas[1]))
  tau=exp(thetas[2])
  y=data[,1]
  n=data[,2]
  N=length(y)
  val = sum(logf(y, n,c(mu,tau)))
  val = val-2*log(1+tau)+thetas[2]
  return(val)
}
```
```{r}
#contour map to get a starting point for laplace approximation
mycontour(transformed_post_betabin,data=data2, 
          limits=c(-4,-3,3.5,8),
          xlab="logit mu",ylab="log tau")

#laplace approximation to get the point at which the function
#is maximized
fit=laplace(transformed_post_betabin,c(-3.5,5.5),data=data2)
fit$mode #-3.520815  5.455601
```



```{r}
#computes difference logp(mu,tau|y)-logq(mu,tau)
betabinomial_t = function(thetas,param){
  data=param$data
  tpar=param$par
  d=transformed_post_betabin(thetas,data)-
    dmt(thetas,mean=c(tpar$m),S=tpar$var,
        df=tpar$df,log=TRUE)
return(d)
}

#the parameters of the t proposal densiy and param
tpar=list(m=fit$mode,var=2*fit$var,df=4)
param=list(data=data2,par=tpar)

start=c(-3.5,5.4) #using the contour graph for this
fit1=laplace(betabinomial_t,start,param)
fit1$mode #the maximum value d occurs at the value
#thetas=(-3.518969, 5.455915), this is the posterior mode.

betabinomial_t(fit1$mode, param)
#the max value of d is -3257.146
```
```{r}
#transform back to original parameterization:
exp(-3.518969)/(1+exp(-3.518969))
#posterior mu 0.0287773
exp(5.455915)
#posterior tau 234.139
```


Now that we have the value d at which the $log p(\mu, \tau|y) - log q(\mu, \tau)$ is maximized, we can perform rejection sampling. 

```{r}
# rejectionsampling = function(func, tpar,d, numsim,data){
#   #sample from bivariate t with 4 df and scale matrix equal
#   #to 2 times the covariance matrix at the mode (proposal 
#   #density)
#   thetas=rmt(numsim,mean=c(tpar$m),S=tpar$var,df=tpar$df)
#   #compute the values of log f and g
#   lf=matrix(0,c(numsim,1))
#   for(i in 1:numsim) lf=logf(thetas[i,],data)
#   
#   lg=dmt(thetas,mean=c(tpar$m),S=tpar$var,df=tpar$df,log=TRUE)
#   
#   #compute acceptance probabilities
#   accept.prob=exp(lf-lg-d)
#   #output the values for which the acceptance prob is greater
#   #than uniform draws
#   thetas[runif(numsim)<accept.prob,]
# }
# 
# accepted = rejectionsampling(transformed_post_betabin,tpar,d=-3257.146,numsim=10000,data=data2)
# dim(accepted)

accepted=rejectsampling(transformed_post_betabin, tpar,   -3257.146,10000,data2)
dim(accepted)
 # we have 51% acceptance rate
```
```{r}
#transform values back
accepted_tr=accepted
accepted_tr[,1]=exp(accepted[,1])/(1+exp(accepted[,1]))
accepted_tr[,2]=exp(accepted[,2])

rej_mu=as.vector(accepted_tr[,1])
rej_tau=accepted_tr[,2]
```

```{r}
#contour plot of the accepted values
par(las=2)
mycontour(transformed_post_betabin,c(-4,-3,3.5,8),data2,xlab="logit mu",ylab="log tau")
points(accepted[,1],accepted[,2])
```

Most draws fall into the inner contour of the exact density.

To answer the question "Are there any counties that are particularly influential in the analysis of the posterior for $\mu$?", we can use the function bayes.influence in the LearnBayes package.

```{r}
#bayes.influence(accepted_tr,data2)
```


Use the accepted samples from rejection sampling to make predictions
```{r}
#install.packages("rmutil")
library(rmutil)

betbin_preds=c()
for(i in 1:1000){
  index=sample(1:length(rej_mu),1,replace=T)
  prediction=rbetabinom(size=future_infec_CA,n=1,
                        m=rej_mu[index],s=rej_tau[index])
betbin_preds=cbind(betbin_preds,prediction)
}
```

```{r}
#plot predicted deaths
par(las=1)
hist(betbin_preds,main = "Predicted number of deaths in CA based on Model 2", 
    xlab = "Number of deaths",
     cex.lab=0.9, cex.axis=0.8, 
     col= brewer.pal(n = 9, name="PuBuGn"))
```

```{r}
mean(betbin_preds)
min(betbin_preds)
max(betbin_preds)

#probability there will be more than 200,000 deaths
sum(betbin_preds>200000)
#57.6 percent
```


Question 4: HIERARCHICAL MODEL

$$y_i \sim Bin(n_i,\theta_i), \theta_i \sim Be(\mu\tau, (1-\mu)\tau), p(\mu,\tau)=(\mu(1-\mu)(1+\tau)^2)^{-1}$$

Write the posterior distribution of all model parameters as $p(\mathbf{\theta}, \mu, \tau | \textbf{y}) = p(\theta | \mu, \tau, \textbf{y})p(\mu, \tau| \textbf{y})$

rejection sampling repeated to sample from $p(\mu,\tau|\textbf{y})$.
```{r}
accepted=rejectsampling(transformed_post_betabin, tpar,   -3257.146,10000,data2)
dim(accepted)
```

```{r}
ca_deaths=sum(data$Deaths)

mu.tau=rej_mu*rej_tau
shape1p=mu.tau+ca_deaths 
shape2p=future_infec_CA-ca_deaths+rej_tau-mu.tau

bet_preds2=c()
for(i in 1:1000){
  index=sample(1:length(rej_mu),1,replace=T)
  prediction=sum(rbeta(n=1,shape1=mu.tau[index],shape2=rej_tau[index]*(1-rej_mu[index])))
bet_preds2=cbind(bet_preds2,prediction)
}
bet_preds2
```

```{r}
#predicted number of deaths
hier_preds=c()
for(i in 1:1000){
  prob=bet_preds2[i]
hier_preds=cbind(hier_preds,sum(rbinom(future_infec_CA,size=1,prob = prob)))
}
hier_preds
```



```{r}
#plot predicted number of deaths
par(las=1)
hist(hier_preds,main = "Predicted number of deaths in CA based on Model 3", 
    xlab = "Number of deaths",
     cex.lab=0.9, cex.axis=0.8, 
     col= brewer.pal(n = 9, name="PuBu"))

mean(hier_preds) #229638
min(hier_preds) #8327
max(hier_preds) #695089

#probability there will be more than 200,000 deaths
sum(hier_preds>200000)
#59.5 percent
```

